# üìù Evaluaci√≥n de Prompts - Docente JavaScript Junior
##  Julian Santamaria
## üìñ Descripci√≥n del Proyecto

Este proyecto utiliza **Promptfoo** para realizar pruebas unitarias automatizadas (**Prompt Unit Testing**) sobre **30 preguntas clave de JavaScript Vanilla**. El objetivo es asegurar que el modelo de lenguaje (Gemini) mantenga un **rol pedag√≥gico consistente** (Docente para Junior de 17-24 a√±os) y que las respuestas cumplan con un **formato de salida estructurado** (Explicaci√≥n Te√≥rica + Caso de Estudio Codificable).

---

## üéØ Objetivos del Proyecto

- ‚úÖ **Validar consistencia pedag√≥gica**: Verificar que el modelo mantenga un tono did√°ctico apropiado para estudiantes junior
- ‚úÖ **Asegurar formato estructurado**: Garantizar que cada respuesta incluya teor√≠a + ejemplo pr√°ctico codificable
- ‚úÖ **Cobertura conceptual completa**: Evaluar 30 conceptos fundamentales de JavaScript Vanilla
- ‚úÖ **Detecci√≥n de errores comunes**: Identificar respuestas que no cumplan con los criterios pedag√≥gicos establecidos

---

## üõ†Ô∏è Configuraci√≥n y Ejecuci√≥n

### Requisitos Previos

- **Node.js** (v16 o superior)
- **Promptfoo** instalado globalmente:
  ```bash
  npm install -g promptfoo
  ```
- **Clave de API de Gemini** v√°lida

### Configuraci√≥n del Proveedor

El proveedor y la clave de API est√°n configurados directamente dentro del archivo `promptfooconfig.yaml` para simplificar la ejecuci√≥n:

| Par√°metro | Valor |
|-----------|-------|
| **Modelo Utilizado** | `google:gemini-2.5-flash` |
| **API Key** | Configurada en `providers:config:apiKey` |
| **Max Tokens** | 2048 (ajustable seg√∫n necesidad) |
| **Temperature** | 0.7 (balance entre creatividad y precisi√≥n) |

---

## üöÄ Comandos de Ejecuci√≥n

### Ejecuci√≥n Completa (Recomendada)

Para ejecutar la evaluaci√≥n completa y evitar errores de tasa l√≠mite (`Rate Limit 429`), utilice el siguiente comando que **limita la concurrencia** y a√±ade un **retraso entre llamadas**:

```bash
# Ejecuci√≥n segura con control de velocidad
promptfoo eval --max-concurrency 1 --delay 2000 --no-cache
```

| Par√°metro | Prop√≥sito |
|-----------|-----------|
| `--max-concurrency 1` | Ejecuta las pruebas **una a una** para evitar saturaci√≥n de la API |
| `--delay 2000` | Espera **2 segundos** entre cada llamada (2000ms) |
| `--no-cache` | Ignora resultados anteriores y fuerza nuevas llamadas (esencial tras corregir errores) |

### Ejecuci√≥n R√°pida (Solo Desarrollo)

Si ya validaste la configuraci√≥n y solo necesitas probar cambios menores:

```bash
promptfoo eval --max-concurrency 3 --delay 1000
```

### Visualizaci√≥n de Resultados

Una vez finalizada la ejecuci√≥n, abra la **interfaz web interactiva** para analizar resultados detallados:

```bash
promptfoo view --yes
```

**Funcionalidades de la interfaz:**
- üìä Ver tasas de aprobaci√≥n por test
- üîç Inspeccionar respuestas completas del modelo
- ‚ö†Ô∏è Identificar fallos de aserciones espec√≠ficas
- üìà Comparar rendimiento entre ejecuciones

---

## üìã Estructura del Proyecto

```
proyecto-evaluacion-js/
‚îÇ
‚îú‚îÄ‚îÄ promptfooconfig.yaml      # Configuraci√≥n principal de Promptfoo
‚îú‚îÄ‚îÄ README.md                  # Este archivo

---

## üìã Contenido de la Evaluaci√≥n

### 1. Instrucci√≥n Base (Rol y Formato)

Todos los **30 casos de prueba** utilizan la **misma instrucci√≥n base** para mantener consistencia:

| Aspecto | Definici√≥n |
|---------|------------|
| **Rol (Actuar como)** | Docente de programaci√≥n para estudiantes de 17-24 a√±os con enfoque en JavaScript |
| **Contexto** | Estudiante inicial de Vanilla JavaScript con dificultades en conceptos fundamentales |
| **Formato de Salida** | Explicaci√≥n pedag√≥gica + Caso de estudio + Mezcla de teor√≠a, ejemplos codificables y texto argumentativo |
| **Tono** | Amigable, paciente, did√°ctico, sin tecnicismos innecesarios |

### 2. Casos de Prueba (30 Tests Unitarios)

El archivo `promptfooconfig.yaml` contiene **30 tests unitarios**, cada uno enfocado en un concepto fundamental de JavaScript. A continuaci√≥n, un resumen de los temas evaluados:

| # | Tema | Pregunta Espec√≠fica (`{{question}}`) | Aserci√≥n Requerida (`icontains`) |
|---|------|--------------------------------------|----------------------------------|
| **1** | Hoisting | Expl√≠came, paso a paso, c√≥mo funciona el `hoisting` en JavaScript... | `eleva` Y `var` |
| **2** | `var`, `let`, `const` | Ay√∫dame a entender la diferencia entre `var`, `let` y `const`. | `scope de bloque` |
| **3** | TDZ/Error `let` | ¬øPor qu√© el siguiente c√≥digo da error y c√≥mo podr√≠a corregirse? | `Dead Zone` Y `antes de inicializar` |
| **4** | Closures | ¬øQu√© es un closure en JavaScript y para qu√© sirve? | `funci√≥n interna` Y `accede` |
| **5** | `this` en funciones | ¬øPor qu√© `this` no funciona como esperaba en mi c√≥digo? | `contexto` Y `flecha` |
| **9** | `return` impl√≠cito | Tengo una funci√≥n que no devuelve el valor esperado, ¬øpor qu√©? | **llm-rubric** (eval√∫a problema de return y punto y coma) |
| **12** | Arrow Functions | ¬øCu√°l es la diferencia entre funciones tradicionales y arrow functions? | `this` Y `l√©xico` |
| **17** | Interpretado/Single-threaded | ¬øQu√© significa que JavaScript sea interpretado y de un solo hilo? | `Event Loop` |
| **22** | Event Bubbling | ¬øQu√© es el event bubbling y c√≥mo puedo controlarlo? | `stopPropagation` |
| **30** | Validaci√≥n Formulario | Ens√©√±ame a validar un formulario simple (nombre y correo). | `e.preventDefault` |

### 3. Tipos de Aserciones Utilizadas

El proyecto utiliza **m√∫ltiples tipos de aserciones** para validar diferentes aspectos:

| Tipo | Uso | Ejemplo |
|------|-----|---------|
| `icontains` | Verifica que la respuesta contenga t√©rminos clave espec√≠ficos | `"eleva" AND "var"` |
| `llm-rubric` | Evaluaci√≥n sem√°ntica compleja usando otro LLM como juez | Eval√∫a si explica correctamente el problema de `return` impl√≠cito |
| `not-icontains` | Asegura que NO se usen t√©rminos inapropiados | Evitar jerga excesivamente t√©cnica |
| `javascript` | Valida que el c√≥digo generado sea sint√°cticamente correcto | Verifica ejemplos ejecutables |

---

## üìä Interpretaci√≥n de Resultados

### M√©tricas Clave

Al ejecutar `promptfoo view`, ver√°s las siguientes m√©tricas:

| M√©trica | Descripci√≥n | Meta |
|---------|-------------|------|
| **Pass Rate** | % de tests aprobados | ‚â• 70% |
| **Assertion Failures** | Cantidad de aserciones fallidas por test | 0 por test |
| **Avg Response Length** | Longitud promedio de respuestas | 800-1500 caracteres |
| **Token Usage** | Tokens consumidos por evaluaci√≥n | Monitorear costos |

### Estados de Tests

- ‚úÖ **PASS**: Todas las aserciones aprobadas
- ‚ùå **FAIL**: Una o m√°s aserciones fallaron
- ‚ö†Ô∏è **WARN**: El test pas√≥ pero con advertencias
- ‚è≠Ô∏è **SKIP**: Test omitido (configuraci√≥n espec√≠fica)

---

## üîß Soluci√≥n de Problemas Comunes

### Error 429 (Rate Limit Exceeded)

**S√≠ntoma**: Errores de tasa l√≠mite al ejecutar m√∫ltiples tests
**Soluci√≥n**:
```bash
promptfoo eval --max-concurrency 1 --delay 3000 --no-cache
```

### Respuestas Inconsistentes

**S√≠ntoma**: El modelo no mantiene el rol pedag√≥gico
**Soluci√≥n**: Revisar y fortalecer la instrucci√≥n base en `promptfooconfig.yaml`

### Aserciones Fallidas Sistem√°ticas

**S√≠ntoma**: Un test falla consistentemente
**Soluci√≥n**: 
1. Revisar si la aserci√≥n es demasiado estricta
2. Verificar que el modelo tenga suficiente contexto
3. Ajustar el `temperature` si las respuestas son muy variables

---

## üéì Pr√≥ximos Pasos

1. **Ampliar cobertura**: A√±adir tests para ES6+, Async/Await, Modules
2. **Comparaci√≥n de modelos**: Evaluar Gemini vs Claude vs GPT-4
3. **M√©tricas pedag√≥gicas**: A√±adir aserciones sobre claridad, ejemplos pr√°cticos
4. **CI/CD**: Integrar con GitHub 